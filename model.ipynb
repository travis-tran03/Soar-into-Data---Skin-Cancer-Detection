{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3b6be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16912a19",
   "metadata": {},
   "source": [
    "### Get Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aac1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image = pd.read_csv('label_and_path.csv')\n",
    "X_image = df_image[:770]['image_path'].values\n",
    "\n",
    "df_meta = pd.read_csv('skin_data.csv')\n",
    "X_meta = df_meta[:770].drop(columns=['target']).values\n",
    "\n",
    "y = df_image[:770]['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd048dbb",
   "metadata": {},
   "source": [
    "### Split Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "975f681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for images\n",
    "X_train_image, X_val_test_image, y_train_image, y_val_test_image = train_test_split(X_image, y, test_size=0.3, stratify=y)\n",
    "X_val_image, X_test_image, y_val_image, y_test_image = train_test_split(X_val_test_image, y_val_test_image, test_size=0.5, stratify=y_val_test_image)\n",
    "\n",
    "# Split for metadata\n",
    "X_train_meta, X_val_test_meta, y_train_meta, y_val_test_meta = train_test_split(X_meta, y, test_size=0.3, stratify=y)\n",
    "X_val_meta, X_test_meta, y_val_meta, y_test_meta = train_test_split(X_val_test_meta, y_val_test_meta, test_size=0.5, stratify=y_val_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db05a085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels that are 1 in y_train_image: 267\n",
      "Number of labels that are 1 in y_val_image: 57\n",
      "Number of labels that are 1 in y_test_image: 57\n",
      "Number of labels that are 1 in y_train_meta: 267\n",
      "Number of labels that are 1 in y_val_meta: 57\n",
      "Number of labels that are 1 in y_test_meta: 57\n"
     ]
    }
   ],
   "source": [
    "count_y_train_image = np.sum(y_train_image == 1)\n",
    "count_y_val_image = np.sum(y_val_image == 1)\n",
    "count_y_test_image = np.sum(y_test_image == 1)\n",
    "\n",
    "count_y_train_meta = np.sum(y_train_meta == 1)\n",
    "count_y_val_meta = np.sum(y_val_meta == 1)\n",
    "count_y_test_meta = np.sum(y_test_meta == 1)\n",
    "\n",
    "print(f\"Number of labels that are 1 in y_train_image: {count_y_train_image}\")\n",
    "print(f\"Number of labels that are 1 in y_val_image: {count_y_val_image}\")\n",
    "print(f\"Number of labels that are 1 in y_test_image: {count_y_test_image}\")\n",
    "\n",
    "print(f\"Number of labels that are 1 in y_train_meta: {count_y_train_meta}\")\n",
    "print(f\"Number of labels that are 1 in y_val_meta: {count_y_val_meta}\")\n",
    "print(f\"Number of labels that are 1 in y_test_meta: {count_y_test_meta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0fbc30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_combined(image_path, metadata, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (128, 128))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return (image, metadata), label\n",
    "\n",
    "def create_combined_dataset(image_paths, metadata, labels, batch_size=32, shuffle=True):\n",
    "    image_paths = tf.constant(image_paths)\n",
    "    metadata = tf.convert_to_tensor(metadata, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((image_paths, metadata, labels))\n",
    "    ds = ds.map(preprocess_combined, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1000)\n",
    "\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc020661",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_combined_dataset(X_train_image, X_train_meta, y_train_image, batch_size=256)\n",
    "val_ds = create_combined_dataset(X_val_image, X_val_meta, y_val_image, batch_size=256, shuffle=False)\n",
    "test_ds = create_combined_dataset(X_test_image, X_test_meta, y_test_image, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2e796",
   "metadata": {},
   "source": [
    "### CNN + MLP ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f37d8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN Model\n",
    "def CNN_model(input_shape=(128, 128, 3)):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Fine-tune the base model\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Define additional layers for your specific task\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = models.Model(inputs=base_model.input, outputs=output, name='cnn_model')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# MLP Model\n",
    "def MLP_model(input_dim):\n",
    "    inputs = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(df_meta.shape[1], activation='relu')(x)\n",
    "    \n",
    "    return models.Model(inputs=inputs, outputs=x, name='metadata_model')\n",
    "\n",
    "\n",
    "# Combined Model\n",
    "def build_combined_model(image_shape, metadata_dim):\n",
    "    cnn_model = CNN_model(image_shape)\n",
    "    mlp_model = MLP_model(metadata_dim)\n",
    "\n",
    "    # Flatten the CNN output to make it 2D\n",
    "    cnn_flattened = layers.Flatten()(cnn_model.output)\n",
    "\n",
    "    # Fusion\n",
    "    combined = layers.concatenate([cnn_flattened, mlp_model.output])\n",
    "    x = layers.Dense(64, activation='relu')(combined)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)  # Connect the output layer to `x`\n",
    "\n",
    "    model = models.Model(inputs=[cnn_model.input, mlp_model.input], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e281a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 6s/step - accuracy: 0.5251 - loss: 51.7868 - val_accuracy: 0.4957 - val_loss: 8.0356\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4813 - loss: 29.8133 - val_accuracy: 0.5043 - val_loss: 19.6198\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4946 - loss: 31.0167 - val_accuracy: 0.5043 - val_loss: 19.6642\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4755 - loss: 27.4085 - val_accuracy: 0.5130 - val_loss: 13.2654\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5236 - loss: 20.4786 - val_accuracy: 0.5217 - val_loss: 6.8514\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4817 - loss: 19.4898 - val_accuracy: 0.5130 - val_loss: 5.3239\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4958 - loss: 17.0438 - val_accuracy: 0.4696 - val_loss: 6.3594\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5096 - loss: 14.5601 - val_accuracy: 0.4783 - val_loss: 6.5506\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5s/step - accuracy: 0.5151 - loss: 13.3135 - val_accuracy: 0.4783 - val_loss: 5.2841\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4918 - loss: 10.9088 - val_accuracy: 0.4783 - val_loss: 3.6584\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4979 - loss: 11.2896 - val_accuracy: 0.4870 - val_loss: 3.0934\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4763 - loss: 11.1891 - val_accuracy: 0.4696 - val_loss: 2.8138\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5047 - loss: 9.0821 - val_accuracy: 0.4870 - val_loss: 2.6554\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5323 - loss: 8.1278 - val_accuracy: 0.4696 - val_loss: 2.8387\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4851 - loss: 8.8591 - val_accuracy: 0.4783 - val_loss: 2.8895\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5370 - loss: 7.4045 - val_accuracy: 0.4696 - val_loss: 2.8232\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4648 - loss: 7.7135 - val_accuracy: 0.5043 - val_loss: 2.4485\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5350 - loss: 6.0079 - val_accuracy: 0.4783 - val_loss: 2.1785\n",
      "Epoch 19/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5s/step - accuracy: 0.5059 - loss: 6.4414 - val_accuracy: 0.4783 - val_loss: 1.9391\n",
      "Epoch 20/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5303 - loss: 5.8044 - val_accuracy: 0.4870 - val_loss: 1.7670\n",
      "Epoch 21/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4876 - loss: 5.6612 - val_accuracy: 0.4783 - val_loss: 1.6638\n",
      "Epoch 22/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5s/step - accuracy: 0.5242 - loss: 5.4716 - val_accuracy: 0.4957 - val_loss: 1.6379\n",
      "Epoch 23/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4943 - loss: 5.5086 - val_accuracy: 0.4609 - val_loss: 1.5774\n",
      "Epoch 24/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4886 - loss: 5.0180 - val_accuracy: 0.4522 - val_loss: 1.5740\n",
      "Epoch 25/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4981 - loss: 4.9013 - val_accuracy: 0.4957 - val_loss: 1.4376\n",
      "Epoch 26/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4938 - loss: 4.2791 - val_accuracy: 0.4783 - val_loss: 1.2616\n",
      "Epoch 27/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4886 - loss: 4.2814 - val_accuracy: 0.5043 - val_loss: 1.1065\n",
      "Epoch 28/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4938 - loss: 4.0289 - val_accuracy: 0.5478 - val_loss: 1.0330\n",
      "Epoch 29/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5068 - loss: 4.0636 - val_accuracy: 0.5478 - val_loss: 1.0364\n",
      "Epoch 30/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4648 - loss: 3.8163 - val_accuracy: 0.5478 - val_loss: 0.9987\n",
      "Epoch 31/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5094 - loss: 3.4108 - val_accuracy: 0.5304 - val_loss: 0.9819\n",
      "Epoch 32/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5181 - loss: 2.8663 - val_accuracy: 0.5130 - val_loss: 0.9494\n",
      "Epoch 33/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5680 - loss: 2.5876 - val_accuracy: 0.4870 - val_loss: 0.8742\n",
      "Epoch 34/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4949 - loss: 2.5646 - val_accuracy: 0.4870 - val_loss: 0.7830\n",
      "Epoch 35/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4922 - loss: 2.8885 - val_accuracy: 0.5217 - val_loss: 0.7346\n",
      "Epoch 36/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5133 - loss: 2.4914 - val_accuracy: 0.4696 - val_loss: 0.7220\n",
      "Epoch 37/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4825 - loss: 2.4772 - val_accuracy: 0.4348 - val_loss: 0.7235\n",
      "Epoch 38/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5128 - loss: 2.0957 - val_accuracy: 0.4348 - val_loss: 0.7157\n",
      "Epoch 39/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4752 - loss: 2.3729 - val_accuracy: 0.5043 - val_loss: 0.7048\n",
      "Epoch 40/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4s/step - accuracy: 0.5018 - loss: 2.1905 - val_accuracy: 0.5478 - val_loss: 0.7044\n",
      "Epoch 41/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4551 - loss: 2.0403 - val_accuracy: 0.5478 - val_loss: 0.7156\n",
      "Epoch 42/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5s/step - accuracy: 0.4852 - loss: 1.9981 - val_accuracy: 0.5391 - val_loss: 0.7110\n",
      "Epoch 43/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5118 - loss: 1.8417 - val_accuracy: 0.5826 - val_loss: 0.6981\n",
      "Epoch 44/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5011 - loss: 1.8019 - val_accuracy: 0.4522 - val_loss: 0.6952\n",
      "Epoch 45/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4999 - loss: 1.6641 - val_accuracy: 0.4957 - val_loss: 0.7072\n",
      "Epoch 46/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4891 - loss: 1.6535 - val_accuracy: 0.5304 - val_loss: 0.7238\n",
      "Epoch 47/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5530 - loss: 1.2815 - val_accuracy: 0.5391 - val_loss: 0.7245\n",
      "Epoch 48/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.5139 - loss: 1.4908 - val_accuracy: 0.5304 - val_loss: 0.7220\n",
      "Epoch 49/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5457 - loss: 1.2781 - val_accuracy: 0.5391 - val_loss: 0.7164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e3f45b7910>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_combined_model(image_shape=(128, 128, 3), metadata_dim=X_train_meta.shape[1])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6bbfc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('combined_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f84aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f621af47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n"
     ]
    }
   ],
   "source": [
    "test_probs = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bedfd9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = np.array(test_probs).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e989015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.505957   0.52496743 0.55580854 0.5391959  0.54385126 0.5409725\n",
      " 0.6562784  0.500085   0.58775985 0.53515255 0.54954433 0.57843685\n",
      " 0.60337913 0.5685998  0.5832405  0.5151526  0.5541109  0.5414109\n",
      " 0.55157906 0.571144   0.5751355  0.5383948  0.5622773  0.5659393\n",
      " 0.515869   0.59866047 0.5580644  0.56414545 0.5623388  0.59507275\n",
      " 0.56094193 0.52263176 0.60943085 0.56496596 0.56139743 0.5344912\n",
      " 0.54053855 0.53427136 0.5170659  0.54069614 0.52486694 0.5605046\n",
      " 0.5426234  0.5245155  0.74670017 0.5689821  0.523491   0.5755012\n",
      " 0.50194776 0.76667523 0.5494616  0.58906364 0.5537907  0.53014946\n",
      " 0.58533835 0.57663405 0.5434215  0.56628776 0.54458255 0.7553722\n",
      " 0.5522603  0.5120162  0.5484512  0.5344702  0.5610119  0.58800435\n",
      " 0.5389935  0.57018864 0.5889834  0.5127261  0.572283  ]\n"
     ]
    }
   ],
   "source": [
    "print(test_probs[test_probs > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a0f8f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689ms/step - accuracy: 0.5862 - loss: 0.6977\n",
      "Test Loss: 0.697702944278717\n",
      "Test Accuracy: 0.5862069129943848\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41a0171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1e3f4067610>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAG2CAYAAACEWASqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAALh5JREFUeJzt3Xt0VPW5//HPDpBJgEy4mZuEGORuBJEgBC9cFAQtBfG0eKAWLKIUFDlU8ShVo5UEbEVQDinSFqIF0VVFrSKSigEVohBBEZCqBIhCCCCQG0lIsn9/IPPrEC4zzEzmst8v116L+e7bE8zimefZ3723YZqmKQAAEJTC/B0AAAC4eCRyAACCGIkcAIAgRiIHACCIkcgBAAhiJHIAAIIYiRwAgCBGIgcAIIiRyAEACGIkcgAAghiJHAAAH8vMzJRhGJo2bZpjzDRNpaenKyEhQZGRkRowYIC2b9/u9rFJ5AAA+NCmTZv04osvqnv37k7jzzzzjObOnasFCxZo06ZNiouL0+DBg1VaWurW8UnkAAD4SFlZmcaOHavFixerZcuWjnHTNDVv3jzNnDlTo0aNUkpKirKzs1VRUaHly5e7dY7G3g66IdXV1Wn//v2KioqSYRj+DgcA4CbTNFVaWqqEhASFhfmutqysrFR1dbXHxzFNs16+sdlsstlsZ91+ypQpuvXWW3XTTTfp6aefdowXFBSoqKhIQ4YMcTpO//79tWHDBt17770uxxTUiXz//v1KTEz0dxgAAA8VFhaqbdu2Pjl2ZWWlIqNaSzUVHh+refPmKisrcxp74oknlJ6eXm/bFStW6PPPP9emTZvqrSsqKpIkxcbGOo3HxsZq7969bsUU1Ik8KipKknTP3z5UeNPmfo4G8I2d35f4OwTAZ2oqy7Xu9z93/HvuC9XV1VJNhWzdxkmNwi/+QLXVKtuRrcLCQtntdsfw2arxwsJCPfDAA1qzZo0iIiLOecgzq/uzVfwXEtSJ/PQPG960uWwkcoSoxpG1/g4B8LkGuTzaOEKGB4ncNE61/u12u1MiP5v8/HwVFxerV69ejrHa2lqtX79eCxYs0K5duySdqszj4+Md2xQXF9er0i+EyW4AAGswJBmGB4vrp7rxxhu1bds2bd261bGkpqZq7Nix2rp1q9q3b6+4uDjl5OQ49qmurta6devUr18/t36soK7IAQBwmRF2avFkfxdFRUUpJSXFaaxZs2Zq3bq1Y3zatGnKyMhQx44d1bFjR2VkZKhp06YaM2aMW2GRyAEA8IMZM2boxIkTmjx5so4ePao+ffpozZo1bs8XIJEDAKzhdIvck/09kJube8bhDKWnp591xrs7SOQAAGtowNZ6QwrMqAAAgEuoyAEA1uDn1rqvkMgBABbhYWs9QJvYgRkVAABwCRU5AMAaaK0DABDEmLUOAAACDRU5AMAaaK0DABDEQrS1TiIHAFhDiFbkgfn1AgAAuISKHABgDbTWAQAIYobhYSKntQ4AALyMihwAYA1hxqnFk/0DEIkcAGANIXqNPDCjAgAALqEiBwBYQ4jeR04iBwBYA611AAAQaKjIAQDWQGsdAIAgFqKtdRI5AMAaQrQiD8yvFwAAwCVU5AAAa6C1DgBAEKO1DgAAAg0VOQDAIjxsrQdo7UsiBwBYA611AAAQaKjIAQDWYBgezloPzIqcRA4AsIYQvf0sMKMCAAAuoSIHAFhDiE52I5EDAKwhRFvrJHIAgDWEaEUemF8vAACAS6jIAQDWQGsdAIAgRmsdAAAEGipyAIAlGIYhIwQrchI5AMASQjWR01oHACCIUZEDAKzB+GnxZP8ARCIHAFgCrXUAABBwqMgBAJYQqhU5iRwAYAkkcgAAglioJnKukQMAEMSoyAEA1sDtZwAABC9a6wAAIOBQkQMALOHUW0w9qci9F4s3kcgBAJZgyMPWeoBmclrrAAAEMSpyAIAlhOpkNxI5AMAaQvT2M1rrAAAEMSpyAIA1eNhaN2mtAwDgP55eI/dsxrvvkMgBAJYQqomca+QAAAQxKnIAgDWE6Kx1EjkAwBJorQMAgIBDRQ4AsIRQrchJ5AAASwjVRE5rHQAAH8jKylL37t1lt9tlt9uVlpam9957z7F+/Pjxji8Xp5e+ffu6fR4qcgCAJTR0Rd62bVvNnj1bHTp0kCRlZ2drxIgR2rJli6644gpJ0tChQ7VkyRLHPuHh4W7HRSIHAFhDA99+Nnz4cKfPs2bNUlZWlvLy8hyJ3GazKS4uzoOgaK0DAOCWkpISp6WqquqC+9TW1mrFihUqLy9XWlqaYzw3N1cxMTHq1KmTJk6cqOLiYrfjIZEDACzhzOvRF7NIUmJioqKjox1LZmbmOc+5bds2NW/eXDabTZMmTdLKlSvVrVs3SdKwYcO0bNkyrV27Vs8++6w2bdqkQYMGufTF4D/RWgcAWIK3rpEXFhbKbrc7xm022zn36dy5s7Zu3apjx47p9ddf17hx47Ru3Tp169ZNo0ePdmyXkpKi1NRUJSUl6d1339WoUaNcjotEDgCwBG8l8tOz0F0RHh7umOyWmpqqTZs2af78+Vq0aFG9bePj45WUlKRvvvnGrbhorQMA0EBM0zxn6/zIkSMqLCxUfHy8W8ekIgcAWEMDz1p/9NFHNWzYMCUmJqq0tFQrVqxQbm6uVq9erbKyMqWnp+v2229XfHy89uzZo0cffVRt2rTRbbfd5tZ5SOQAAEto6PvIDx48qDvvvFMHDhxQdHS0unfvrtWrV2vw4ME6ceKEtm3bppdeeknHjh1TfHy8Bg4cqFdffVVRUVFunYdEDgCAD/z1r38957rIyEi9//77XjkPiRz15K/frN07duvo4aNq3KSx4hLjlDakn1q2aenYprqqWnk5G7X7692qrKiUvYVd3ft2V8o1V/oxcsA1Q7vGaGi3WMVEnZptvO9ohV77/Ad9XnhcktT3spa6uWuMLr+kmewRTfQ/r29TwZEKf4YML+BZ6z6ycOFCJScnKyIiQr169dJHH33k75Asb/+e/Urpc6Vuv+e/9PNxI1RXV6e3s9/WyeqTjm0+Wf2x9n67T4NvH6wx949Vj349tH7Veu3euduPkQOuOVJerZc/26cHV36lB1d+pW37S/TIkE5KbBkpSYpo0kg7D5bppU8L/RwpvMmQh/eRe3SB3Xf8mshfffVVTZs2TTNnztSWLVt0/fXXa9iwYdq3b58/w7K84b/+ubr27KrWMa3VJq6NbrztJpUdL9Wh/f//iUNFhUXqclUXXZrcVvaWdl2RmqI2sW2ctgEC1aZ9x5RfeFz7j1dq//FKLdv0vSpP1qlzTHNJUu43h/Xa5z/oyx+O+zlS4ML8msjnzp2rCRMm6O6771bXrl01b948JSYmKisry59h4QxVladulbBFRjjG4tvFa8/XBSorKZNpmvp+9/c6duSYEju081eYwEUJM6TrLm+liCZh+vpgmb/DgQ9568lugcZv18irq6uVn5+v//3f/3UaHzJkiDZs2OCnqHAm0zT1yeqPFd8uXq1jWzvGr7/lBn349lpl/2mpwsLCJEMaNGKQEpIS/Bgt4LqklpGaPfIKhTcKU+XJWs1e8299f+yEv8OCLzXw7WcNxW+J/PDhw6qtrVVsbKzTeGxsrIqKis66T1VVldON9CUlJT6NEdL6d9fryMEjGjXhdqfxL/O+0MHCg7plzK2KahGl/Xv3a90769Q0qpkSL0/0U7SA6344Xqn/eX2bmoU3VlpyK00dcLlm/nMnyRxBx++T3c5sVZimec72RWZmptOD6hMTSRi+tP7dddrzdYFG3nWbmkc3d4zXnKxR3gd5unbodUrukqw2cW3UvU93dUjpqK2fbPFjxIDraupMFZVU6bvD5fr7pkLtOVKh4VfGXnhHBK1Qba37LZG3adNGjRo1qld9FxcX16vST3vkkUd0/Phxx1JYyIxSXzBNU+vfWafdO3ZrxF0jZW/p/Ezhuto61dXW1fulNsIMmabZkKECXmMYUpMwv9c28CESuZeFh4erV69eysnJcRrPyclRv379zrqPzWZzPKzenYfWwz3r31mnXV/u0uD/GqIm4U1UXlqu8tJy1ZyskSSFR4Qr4bIEbVjziX4o+F4lR0u0c8tO7dr6tdp3be/n6IEL+1XvtuoWF6WY5uFKahmpsb3b6op4u9Z9e1iS1NzWSMmtmzpuR0uIjlBy66ZqEdnEn2HDQ4bh+RKI/PpAmOnTp+vOO+9Uamqq0tLS9OKLL2rfvn2aNGmSP8OyvK82fSVJenPJSqfxQbfdqK49u0qShvziZuX9a6Ny/pGjyhOVimoRpb439tUVvVMaPF7AXS0im2jawMvVsmkTlVfXau+RCj313tf64odT826uSWqpqQMud2z/0E0dJUkr8r/Xivwf/BIzcC5+TeSjR4/WkSNH9NRTT+nAgQNKSUnRqlWrlJSU5M+wLG/KU/ddcJtmUc104203NUA0gPctWF9w3vVr/31Ya/99uIGiQUM5VVV78mQ3LwbjRX5/ROvkyZM1efJkf4cBAAh1nrbHAzSRM7MDAIAg5veKHACAhhCqL00hkQMALMHTmecBmsdprQMAEMyoyAEAlhAWZigs7OLLatODfX2JRA4AsARa6wAAIOBQkQMALIFZ6wAABLFQba2TyAEAlhCqFTnXyAEACGJU5AAASwjVipxEDgCwhFC9Rk5rHQCAIEZFDgCwBEMettYD9D2mJHIAgCXQWgcAAAGHihwAYAnMWgcAIIjRWgcAAAGHihwAYAm01gEACGKh2lonkQMALCFUK3KukQMAEMSoyAEA1uBhaz1AH+xGIgcAWAOtdQAAEHCoyAEAlsCsdQAAghitdQAAEHCoyAEAlkBrHQCAIEZrHQAABBwqcgCAJYRqRU4iBwBYAtfIAQAIYqFakXONHACAIEZFDgCwBFrrAAAEMVrrAAAg4FCRAwAswZCHrXWvReJdJHIAgCWEGYbCPMjknuzrS7TWAQAIYlTkAABLYNY6AABBLFRnrZPIAQCWEGacWjzZPxBxjRwAgCBGRQ4AsAbDw/Z4gFbkJHIAgCWE6mQ3WusAAAQxKnIAgCUYP/3nyf6BiEQOALAEZq0DAICAQ0UOALAESz8Q5vnnn3f5gFOnTr3oYAAA8JVQnbXuUiJ/7rnnXDqYYRgkcgAAGpBLibygoMDXcQAA4FO8xvQM1dXV2rVrl2pqarwZDwAAPnG6te7JEojcTuQVFRWaMGGCmjZtqiuuuEL79u2TdOra+OzZs70eIAAA3nB6spsnizuysrLUvXt32e122e12paWl6b333nOsN01T6enpSkhIUGRkpAYMGKDt27e7/XO5ncgfeeQRffHFF8rNzVVERIRj/KabbtKrr77qdgAAAISitm3bavbs2dq8ebM2b96sQYMGacSIEY5k/cwzz2ju3LlasGCBNm3apLi4OA0ePFilpaVuncftRP7mm29qwYIFuu6665y+nXTr1k3fffedu4cDAKBBNHRrffjw4brlllvUqVMnderUSbNmzVLz5s2Vl5cn0zQ1b948zZw5U6NGjVJKSoqys7NVUVGh5cuXu3UetxP5oUOHFBMTU2+8vLw8YO+xAwDg9GQ3TxZJKikpcVqqqqoueO7a2lqtWLFC5eXlSktLU0FBgYqKijRkyBDHNjabTf3799eGDRvc+7nc+2uQevfurXfffdfx+XTyXrx4sdLS0tw9HAAAQSUxMVHR0dGOJTMz85zbbtu2Tc2bN5fNZtOkSZO0cuVKdevWTUVFRZKk2NhYp+1jY2Md61zl9pPdMjMzNXToUO3YsUM1NTWaP3++tm/fro0bN2rdunXuHg4AgAZhyLNXip/et7CwUHa73TFus9nOuU/nzp21detWHTt2TK+//rrGjRvnlCvP7GSbpul2d9vtirxfv3765JNPVFFRocsvv1xr1qxRbGysNm7cqF69erl7OAAAGoS3Zq2fnoV+ejlfIg8PD1eHDh2UmpqqzMxM9ejRQ/Pnz1dcXJwk1au+i4uL61XpF3JRz1q/8sorlZ2dfTG7AgBgWaZpqqqqSsnJyYqLi1NOTo569uwp6dTzWdatW6c5c+a4dcyLSuS1tbVauXKldu7cKcMw1LVrV40YMUKNG/MOFgBAYGro15g++uijGjZsmBITE1VaWqoVK1YoNzdXq1evlmEYmjZtmjIyMtSxY0d17NhRGRkZatq0qcaMGePWedzOvF999ZVGjBihoqIide7cWZL073//W5dcconefvttXXnlle4eEgAAn2vot58dPHhQd955pw4cOKDo6Gh1795dq1ev1uDBgyVJM2bM0IkTJzR58mQdPXpUffr00Zo1axQVFeXWedxO5HfffbeuuOIKbd68WS1btpQkHT16VOPHj9c999yjjRs3untIAABCzl//+tfzrjcMQ+np6UpPT/foPG4n8i+++MIpiUtSy5YtNWvWLPXu3dujYAAA8KVQfNyJ27PWO3furIMHD9YbLy4uVocOHbwSFAAA3tbQz1pvKC5V5CUlJY4/Z2RkaOrUqUpPT1ffvn0lSXl5eXrqqafcnmkHAEBDaejJbg3FpUTeokULp28ipmnql7/8pWPMNE1Jp54rW1tb64MwAQDA2biUyD/88ENfxwEAgE819Kz1huJSIu/fv7+v4wAAwKe89YjWQHPRT3CpqKjQvn37VF1d7TTevXt3j4MCAACucTuRHzp0SHfddZfee++9s67nGjkAIBD956tIL3b/QOT27WfTpk3T0aNHlZeXp8jISK1evVrZ2dnq2LGj3n77bV/ECACAxwzD8yUQuV2Rr127Vm+99ZZ69+6tsLAwJSUlafDgwbLb7crMzNStt97qizgBAMBZuF2Rl5eXKyYmRpLUqlUrHTp0SNKpN6J9/vnn3o0OAAAvCdUHwlzUk9127dolSbrqqqu0aNEi/fDDD/rzn/+s+Ph4rwcIAIA30Fr/ybRp03TgwAFJ0hNPPKGbb75Zy5YtU3h4uJYuXert+AAAwHm4ncjHjh3r+HPPnj21Z88eff3112rXrp3atGnj1eAAAPCWUJ21ftH3kZ/WtGlTXX311d6IBQAAn/G0PR6gedy1RD59+nSXDzh37tyLDgYAAF+x9CNat2zZ4tLBAvWHBAAgVIXES1MeG9xJdrvd32EAPtGy933+DgHwGbO2+sIbeUmYLuJWrTP2D0QeXyMHACAYhGprPVC/YAAAABdQkQMALMEwpDCrzloHACDYhXmYyD3Z15dorQMAEMQuKpG//PLLuvbaa5WQkKC9e/dKkubNm6e33nrLq8EBAOAtvDTlJ1lZWZo+fbpuueUWHTt2TLW1tZKkFi1aaN68ed6ODwAArzjdWvdkCURuJ/IXXnhBixcv1syZM9WoUSPHeGpqqrZt2+bV4AAAwPm5PdmtoKBAPXv2rDdus9lUXl7ulaAAAPC2UH3WutsVeXJysrZu3Vpv/L333lO3bt28ERMAAF53+u1nniyByO2K/KGHHtKUKVNUWVkp0zT12Wef6ZVXXlFmZqb+8pe/+CJGAAA8xiNaf3LXXXeppqZGM2bMUEVFhcaMGaNLL71U8+fP1x133OGLGAEAwDlc1ANhJk6cqIkTJ+rw4cOqq6tTTEyMt+MCAMCrQvUauUdPdmvTpo234gAAwKfC5Nl17jAFZiZ3O5EnJyef96b43bt3exQQAABwnduJfNq0aU6fT548qS1btmj16tV66KGHvBUXAABeRWv9Jw888MBZx//v//5Pmzdv9jggAAB8gZemXMCwYcP0+uuve+twAADABV57jek//vEPtWrVyluHAwDAq069j/ziy+qQaa337NnTabKbaZoqKirSoUOHtHDhQq8GBwCAt3CN/CcjR450+hwWFqZLLrlEAwYMUJcuXbwVFwAAcIFbibympkaXXXaZbr75ZsXFxfkqJgAAvI7JbpIaN26s3/72t6qqqvJVPAAA+IThhf8Ckduz1vv06aMtW7b4IhYAAHzmdEXuyRKI3L5GPnnyZP3ud7/T999/r169eqlZs2ZO67t37+614AAAwPm5nMh/85vfaN68eRo9erQkaerUqY51hmHINE0ZhqHa2lrvRwkAgIdC9Rq5y4k8Oztbs2fPVkFBgS/jAQDAJwzDOO+7QlzZPxC5nMhN05QkJSUl+SwYAADgHreukQfqtxEAAC7E8q11SerUqdMFk/mPP/7oUUAAAPgCT3aT9OSTTyo6OtpXsQAAADe5lcjvuOMOxcTE+CoWAAB8JswwPHppiif7+pLLiZzr4wCAYBaq18hdfrLb6VnrAAAgcLhckdfV1fkyDgAAfMvDyW4B+qh19x/RCgBAMAqToTAPsrEn+/oSiRwAYAmhevuZ228/AwAAgYOKHABgCaE6a51EDgCwhFC9j5zWOgAAQYyKHABgCaE62Y1EDgCwhDB52FoP0NvPaK0DABDEqMgBAJZAax0AgCAWJs/a0IHawg7UuAAAgAuoyAEAlmAYhkev5A7U13mTyAEAlmDIsxeYBWYaJ5EDACyCJ7sBAICAQyIHAFiG4cHirszMTPXu3VtRUVGKiYnRyJEjtWvXLqdtxo8f77h2f3rp27evW+chkQMALOH0feSeLO5Yt26dpkyZory8POXk5KimpkZDhgxReXm503ZDhw7VgQMHHMuqVavcOg/XyAEA8IHVq1c7fV6yZIliYmKUn5+vG264wTFus9kUFxd30eehIgcAWMKZLeyLWSSppKTEaamqqnLp/MePH5cktWrVymk8NzdXMTEx6tSpkyZOnKji4mK3fi4SOQDAEsK8sEhSYmKioqOjHUtmZuYFz22apqZPn67rrrtOKSkpjvFhw4Zp2bJlWrt2rZ599llt2rRJgwYNcvnLgURrHQAAtxQWFsputzs+22y2C+5z33336csvv9THH3/sND569GjHn1NSUpSamqqkpCS9++67GjVqlEvxkMgBAJbgrSe72e12p0R+Iffff7/efvttrV+/Xm3btj3vtvHx8UpKStI333zj8vFJ5AAAS2joJ7uZpqn7779fK1euVG5urpKTky+4z5EjR1RYWKj4+HiXz8M1cgAAfGDKlCn6+9//ruXLlysqKkpFRUUqKirSiRMnJEllZWV68MEHtXHjRu3Zs0e5ubkaPny42rRpo9tuu83l81CRAwAsoaFfmpKVlSVJGjBggNP4kiVLNH78eDVq1Ejbtm3TSy+9pGPHjik+Pl4DBw7Uq6++qqioKJfPQyIHAFhCQ7+P3DTN866PjIzU+++/f/EB/YREDgCwhFB9jSnXyAEACGJU5AAAS+B95AAABLGLefHJmfsHIlrrAAAEMSpyAIAlhMlQmAcNck/29SUSOQDAEmitAwCAgENFDgCwBOOn/zzZPxCRyAEAlkBrHQAABBwqcgCAJRgezlqntQ4AgB+FamudRA4AsIRQTeRcIwcAIIhRkQMALIHbzwAACGJhxqnFk/0DEa11AACCGBU5AMASaK0DABDEmLUOAAACDhU5AMASDHnWHg/QgpxEDgCwBmatAwCAgENFjno++fxbvfDyv/TF1/tUdLhEf//jRN06oIdjfcve9511vyenjtTUO29qqDABr/if8UP0+JSfK+uVD/Xo3Ncd4w9PvEXjbrtWLaIilb99rx565lV9vbvIj5HCU6E6a92vFfn69es1fPhwJSQkyDAMvfnmm/4MBz+pOFGllE6X6pmHfnnW9V+/l+G0LHhsrAzD0M8HXtWwgQIe6tmtncaN7Kev/v290/gDv75Jk8cM1Iw/vqYbx/9RxUdK9MaC+9W8qc1PkcIbTs9a92QJRH5N5OXl5erRo4cWLFjgzzBwhsHXXqHf/3a4hg+66qzrY9vYnZZV67fp+l4ddVnbNg0bKOCBZpHhevGp8Xog4xUdKz3htG7Sfw/U3CXv650Pv9DO7w7ot+kvq2lEE/3Xzal+ihbeYHhhCUR+TeTDhg3T008/rVGjRvkzDHig+EiJ1nz8lX41Is3foQBu+eOM0VrzyVda99kup/GkS1srrk201uZ97RirPlmjTz7/Vtd0b9/QYQIXFFTXyKuqqlRVVeX4XFJS4sdoIEmvvPupmjeL0HDa6ggiowb3Uo8uiRo07pl662Jb2yVJh34sdRov/rFUiXGtGiQ++EaYDIV50B8PC9CaPKhmrWdmZio6OtqxJCYm+jsky1v2dp5+MTRVEbYm/g4FcMmlsS2U+bvbde/j2aqqrjnndqZpOn02DMmUeY6tEQxorQeARx55RMePH3cshYWF/g7J0jZs+Vbf7D2oO0f083cogMt6dGmnmNZ2ffjSDB3aOF+HNs7Xdb066t7R/XVo43wVHzlVicf8VJmfdknLKB06Unq2QwJ+FVStdZvNJpuNWaOB4u9vbdRVXRN1Zae2/g4FcNn6TbvU745ZTmMLHv+VvtlzUPNfytGeHw6r6PBxDezTRdt+ms3epHEjXXt1B6W/8JY/Qoa3eFpWB2hJHlSJHA2jrKJKBYWHHJ/37j+ibbu+V4vopo5rhCVlJ/TWB1v0h2m3+StM4KKUVVRp53cHnMYqTlTrx+PljvE/v/Khpt81RN8VFmt34SFNH3+zKipP6h/vb/ZHyPCSUL2P3K+JvKysTN9++63jc0FBgbZu3apWrVqpXbt2fozM2rbu3Kvhk553fJ753BuSpP++tY8Wpt8pSXpjTb5M09Tt3I6DEDT/pX8pwhauPz08Wi2imip/+x7dfv8ClVVUXXhnoIEZ5pkzOhpQbm6uBg4cWG983LhxWrp06QX3LykpUXR0tA4eOS673X7B7YFgdK4n6QGhwKytVtW2xTp+3Hf/jp/OFR9s3afmURd/jrLSEt14VTufxnox/FqRDxgwoN7MUAAAfCFEL5EH16x1AADgjMluAABrCNGSnEQOALAEZq0DABDEPH2DGW8/AwAAXkdFDgCwhBC9RE4iBwBYRIhmclrrAAAEMSpyAIAlMGsdAIAgxqx1AAAQcKjIAQCWEKJz3UjkAACLCNFMTmsdAIAgRkUOALAEZq0DABDEQnXWOokcAGAJIXqJnGvkAAAEMypyAIA1hGhJTiIHAFhCqE52o7UOAEAQoyIHAFgCs9YBAAhiIXqJnNY6AADBjIocAGANIVqSk8gBAJbArHUAABBwqMgBAJbArHUAAIJYiF4iJ5EDACwiRDM518gBAAhiVOQAAEsI1VnrJHIAgDV4ONktQPM4rXUAAHwhMzNTvXv3VlRUlGJiYjRy5Ejt2rXLaRvTNJWenq6EhARFRkZqwIAB2r59u1vnIZEDACzB8MLijnXr1mnKlCnKy8tTTk6OampqNGTIEJWXlzu2eeaZZzR37lwtWLBAmzZtUlxcnAYPHqzS0lKXz0NrHQBgDQ08a3316tVOn5csWaKYmBjl5+frhhtukGmamjdvnmbOnKlRo0ZJkrKzsxUbG6vly5fr3nvvdek8VOQAADSA48ePS5JatWolSSooKFBRUZGGDBni2MZms6l///7asGGDy8elIgcAWIK3Zq2XlJQ4jdtsNtlstvPua5qmpk+fruuuu04pKSmSpKKiIklSbGys07axsbHau3evy3FRkQMALOH0I1o9WSQpMTFR0dHRjiUzM/OC577vvvv05Zdf6pVXXjlLXM5fLkzTrDd2PlTkAAC4obCwUHa73fH5QtX4/fffr7ffflvr169X27ZtHeNxcXGSTlXm8fHxjvHi4uJ6Vfr5UJEDACzBW7PW7Xa703KuRG6apu677z698cYbWrt2rZKTk53WJycnKy4uTjk5OY6x6upqrVu3Tv369XP556IiBwBYQwPPWp8yZYqWL1+ut956S1FRUY5r4tHR0YqMjJRhGJo2bZoyMjLUsWNHdezYURkZGWratKnGjBnj8nlI5AAAS2joR7RmZWVJkgYMGOA0vmTJEo0fP16SNGPGDJ04cUKTJ0/W0aNH1adPH61Zs0ZRUVEun4dEDgCAD5imecFtDMNQenq60tPTL/o8JHIAgCUY8uxZ6wH6qHUSOQDAGkL0deTMWgcAIJhRkQMALOE/H+pysfsHIhI5AMAiQrO5TmsdAIAgRkUOALAEWusAAASx0Gys01oHACCoUZEDACyB1joAAEGsoZ+13lBI5AAAawjRi+RcIwcAIIhRkQMALCFEC3ISOQDAGkJ1shutdQAAghgVOQDAEpi1DgBAMAvRi+S01gEACGJU5AAASwjRgpxEDgCwBmatAwCAgENFDgCwCM9mrQdqc51EDgCwBFrrAAAg4JDIAQAIYrTWAQCWEKqtdRI5AMASQvURrbTWAQAIYlTkAABLoLUOAEAQC9VHtNJaBwAgiFGRAwCsIURLchI5AMASmLUOAAACDhU5AMASmLUOAEAQC9FL5CRyAIBFhGgm5xo5AABBjIocAGAJoTprnUQOALAEJrsFINM0JUmlJSV+jgTwHbO22t8hAD5z+vf79L/nvlTiYa7wdH9fCepEXlpaKknqkJzo50gAAJ4oLS1VdHS0T44dHh6uuLg4dfRCroiLi1N4eLgXovIew2yIr0E+UldXp/379ysqKkpGoPY8QkxJSYkSExNVWFgou93u73AAr+L3u+GZpqnS0lIlJCQoLMx3868rKytVXe15dys8PFwRERFeiMh7groiDwsLU9u2bf0dhiXZ7Xb+oUPI4ve7YfmqEv9PERERAZeAvYXbzwAACGIkcgAAghiJHG6x2Wx64oknZLPZ/B0K4HX8fiMYBfVkNwAArI6KHACAIEYiBwAgiJHIAQAIYiRyAACCGIkcLlu4cKGSk5MVERGhXr166aOPPvJ3SIBXrF+/XsOHD1dCQoIMw9Cbb77p75AAl5HI4ZJXX31V06ZN08yZM7VlyxZdf/31GjZsmPbt2+fv0ACPlZeXq0ePHlqwYIG/QwHcxu1ncEmfPn109dVXKysryzHWtWtXjRw5UpmZmX6MDPAuwzC0cuVKjRw50t+hAC6hIscFVVdXKz8/X0OGDHEaHzJkiDZs2OCnqAAAEokcLjh8+LBqa2sVGxvrNB4bG6uioiI/RQUAkEjkcMOZr4o1TZPXxwKAn5HIcUFt2rRRo0aN6lXfxcXF9ap0AEDDIpHjgsLDw9WrVy/l5OQ4jefk5Khfv35+igoAIEmN/R0AgsP06dN15513KjU1VWlpaXrxxRe1b98+TZo0yd+hAR4rKyvTt99+6/hcUFCgrVu3qlWrVmrXrp0fIwMujNvP4LKFCxfqmWee0YEDB5SSkqLnnntON9xwg7/DAjyWm5urgQMH1hsfN26cli5d2vABAW4gkQMAEMS4Rg4AQBAjkQMAEMRI5AAABDESOQAAQYxEDgBAECORAwAQxEjkAAAEMRI54KH09HRdddVVjs/jx4/3y7us9+zZI8MwtHXr1nNuc9lll2nevHkuH3Pp0qVq0aKFx7EZhqE333zT4+MAqI9EjpA0fvx4GYYhwzDUpEkTtW/fXg8++KDKy8t9fu758+e7/DQwV5IvAJwPz1pHyBo6dKiWLFmikydP6qOPPtLdd9+t8vJyZWVl1dv25MmTatKkiVfOGx0d7ZXjAIArqMgRsmw2m+Li4pSYmKgxY8Zo7Nixjvbu6Xb43/72N7Vv3142m02maer48eO65557FBMTI7vdrkGDBumLL75wOu7s2bMVGxurqKgoTZgwQZWVlU7rz2yt19XVac6cOerQoYNsNpvatWunWbNmSZKSk5MlST179pRhGBowYIBjvyVLlqhr166KiIhQly5dtHDhQqfzfPbZZ+rZs6ciIiKUmpqqLVu2uP13NHfuXF155ZVq1qyZEhMTNXnyZJWVldXb7s0331SnTp0UERGhwYMHq7Cw0Gn9P//5T/Xq1UsRERFq3769nnzySdXU1LgdDwD3kchhGZGRkTp58qTj87fffqvXXntNr7/+uqO1feutt6qoqEirVq1Sfn6+rr76at1444368ccfJUmvvfaannjiCc2aNUubN29WfHx8vQR7pkceeURz5szRY489ph07dmj58uWO97h/9tlnkqR//etfOnDggN544w1J0uLFizVz5kzNmjVLO3fuVEZGhh577DFlZ2dLksrLy/Wzn/1MnTt3Vn5+vtLT0/Xggw+6/XcSFham559/Xl999ZWys7O1du1azZgxw2mbiooKzZo1S9nZ2frkk09UUlKiO+64w7H+/fff169+9StNnTpVO3bs0KJFi7R06VLHlxUAPmYCIWjcuHHmiBEjHJ8//fRTs3Xr1uYvf/lL0zRN84knnjCbNGliFhcXO7b54IMPTLvdblZWVjod6/LLLzcXLVpkmqZppqWlmZMmTXJa36dPH7NHjx5nPXdJSYlps9nMxYsXnzXOgoICU5K5ZcsWp/HExERz+fLlTmN/+MMfzLS0NNM0TXPRokVmq1atzPLycsf6rKyssx7rPyUlJZnPPffcOde/9tprZuvWrR2flyxZYkoy8/LyHGM7d+40JZmffvqpaZqmef3115sZGRlOx3n55ZfN+Ph4x2dJ5sqVK895XgAXj2vkCFnvvPOOmjdvrpqaGp08eVIjRozQCy+84FiflJSkSy65xPE5Pz9fZWVlat26tdNxTpw4oe+++06StHPnznrvYE9LS9OHH3541hh27typqqoq3XjjjS7HfejQIRUWFmrChAmaOHGiY7ympsZx/X3nzp3q0aOHmjZt6hSHuz788ENlZGRox44dKikpUU1NjSorK1VeXq5mzZpJkho3bqzU1FTHPl26dFGLFi20c+dOXXPNNcrPz9emTZucKvDa2lpVVlaqoqLCKUYA3kciR8gaOHCgsrKy1KRJEyUkJNSbzHY6UZ1WV1en+Ph45ebm1jvWxd6CFRkZ6fY+dXV1kk611/v06eO0rlGjRpIk0wtvH967d69uueUWTZo0SX/4wx/UqlUrffzxx5owYYLTJQjp1O1jZzo9VldXpyeffFKjRo2qt01ERITHcQI4PxI5QlazZs3UoUMHl7e/+uqrVVRUpMaNG+uyyy476zZdu3ZVXl6efv3rXzvG8vLyznnMjh07KjIyUh988IHuvvvueuvDw8MlnapgT4uNjdWll16q3bt3a+zYsWc9brdu3fTyyy/rxIkTji8L54vjbDZv3qyamho9++yzCgs7NV3mtddeq7ddTU2NNm/erGuuuUaStGvXLh07dkxdunSRdOrvbdeuXW79XQPwHhI58JObbrpJaWlpGjlypObMmaPOnTtr//79WrVqlUaOHKnU1FQ98MADGjdunFJTU3Xddddp2bJl2r59u9q3b3/WY0ZEROjhhx/WjBkzFB4ermuvvVaHDh3S9u3bNWHCBMXExCgyMlKrV69W27ZtFRERoejoaKWnp2vq1Kmy2+0aNmyYqqqqtHnzZh09elTTp0/XmDFjNHPmTE2YMEG///3vtWfPHv3pT39y6+e9/PLLVVNToxdeeEHDhw/XJ598oj//+c/1tmvSpInuv/9+Pf/882rSpInuu+8+9e3b15HYH3/8cf3sZz9TYmKifvGLXygsLExffvmltm3bpqefftr9/xEA3MKsdeAnhmFo1apVuuGGG/Sb3/xGnTp10h133KE9e/Y4ZpmPHj1ajz/+uB5++GH16tVLe/fu1W9/+9vzHvexxx7T7373Oz3++OPq2rWrRo8ereLiYkmnrj8///zzWrRokRISEjRixAhJ0t13362//OUvWrp0qa688kr1799fS5cuddyu1rx5c/3zn//Ujh071LNnT82cOVNz5sxx6+e96qqrNHfuXM2ZM0cpKSlatmyZMjMz623XtGlTPfzwwxozZozS0tIUGRmpFStWONbffPPNeuedd5STk6PevXurb9++mjt3rpKSktyKB8DFMUxvXGwDAAB+QUUOAEAQI5EDABDESOQAAAQxEjkAAEGMRA4AQBAjkQMAEMRI5AAABDESOQAAQYxEDgBAECORAwAQxEjkAAAEMRI5AABB7P8BLSiRGB87txoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Assuming test_probs contains the predicted probabilities, we convert them to binary predictions\n",
    "y_pred = (test_probs > 0.5).astype(int)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test_image, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a98d42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set - Labels with 1: 267, Labels with 0: 272\n",
      "Validation set - Labels with 1: 57, Labels with 0: 58\n",
      "Test set - Labels with 1: 57, Labels with 0: 59\n"
     ]
    }
   ],
   "source": [
    "# Count labels with 1 and 2 in each set\n",
    "count_y_train_image_1 = np.sum(y_train_image == 1)\n",
    "count_y_train_image_2 = np.sum(y_train_image == 0)\n",
    "\n",
    "count_y_val_image_1 = np.sum(y_val_image == 1)\n",
    "count_y_val_image_2 = np.sum(y_val_image == 0)\n",
    "\n",
    "count_y_test_image_1 = np.sum(y_test_image == 1)\n",
    "count_y_test_image_2 = np.sum(y_test_image == 0)\n",
    "\n",
    "print(f\"Train set - Labels with 1: {count_y_train_image_1}, Labels with 0: {count_y_train_image_2}\")\n",
    "print(f\"Validation set - Labels with 1: {count_y_val_image_1}, Labels with 0: {count_y_val_image_2}\")\n",
    "print(f\"Test set - Labels with 1: {count_y_test_image_1}, Labels with 0: {count_y_test_image_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fe85d6",
   "metadata": {},
   "source": [
    "### Auto Encoder ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b85fa46",
   "metadata": {},
   "source": [
    "# Define the convolutional autoencoder architecture\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoding layers\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Decoding layers\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(input_shape[2], (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Encoder model\n",
    "encoder = Model(input_layer, encoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=1, batch_size=256, shuffle=True, validation_data=(X_val, X_val), callback=[early_stopping_callback])\n",
    "\n",
    "# Encode the validation data\n",
    "encoded_val = encoder.predict(X_val)\n",
    "\n",
    "# Detect anomalies using reconstruction loss\n",
    "reconstructed_val = autoencoder.predict(X_val)\n",
    "reconstruction_error = np.mean((X_val - reconstructed_val) ** 2, axis=(1, 2, 3))\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "threshold = reconstruction_error.mean() + 2 * reconstruction_error.std()\n",
    "\n",
    "# Identify anomalies\n",
    "anomalies = reconstruction_error > threshold\n",
    "print(\"Number of anomalies detected:\", anomalies.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d61fe7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
