{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a3b6be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16912a19",
   "metadata": {},
   "source": [
    "### Get Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9aac1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image = pd.read_csv('label_and_path.csv')\n",
    "X_image = df_image[:770]['image_path'].values\n",
    "\n",
    "df_meta = pd.read_csv('skin_data.csv')\n",
    "X_meta = df_meta[:770].drop(columns=['target']).values\n",
    "\n",
    "y = df_image[:770]['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd048dbb",
   "metadata": {},
   "source": [
    "### Split Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "975f681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for images\n",
    "X_train_image, X_val_test_image, y_train_image, y_val_test_image = train_test_split(X_image, y, test_size=0.3, stratify=y)\n",
    "X_val_image, X_test_image, y_val_image, y_test_image = train_test_split(X_val_test_image, y_val_test_image, test_size=0.5, stratify=y_val_test_image)\n",
    "\n",
    "# Split for metadata\n",
    "X_train_meta, X_val_test_meta, y_train_meta, y_val_test_meta = train_test_split(X_meta, y, test_size=0.3, stratify=y)\n",
    "X_val_meta, X_test_meta, y_val_meta, y_test_meta = train_test_split(X_val_test_meta, y_val_test_meta, test_size=0.5, stratify=y_val_test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "db05a085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels that are 1 in y_train_image: 267\n",
      "Number of labels that are 1 in y_val_image: 57\n",
      "Number of labels that are 1 in y_test_image: 57\n",
      "Number of labels that are 1 in y_train_meta: 267\n",
      "Number of labels that are 1 in y_val_meta: 57\n",
      "Number of labels that are 1 in y_test_meta: 57\n"
     ]
    }
   ],
   "source": [
    "count_y_train_image = np.sum(y_train_image == 1)\n",
    "count_y_val_image = np.sum(y_val_image == 1)\n",
    "count_y_test_image = np.sum(y_test_image == 1)\n",
    "\n",
    "count_y_train_meta = np.sum(y_train_meta == 1)\n",
    "count_y_val_meta = np.sum(y_val_meta == 1)\n",
    "count_y_test_meta = np.sum(y_test_meta == 1)\n",
    "\n",
    "print(f\"Number of labels that are 1 in y_train_image: {count_y_train_image}\")\n",
    "print(f\"Number of labels that are 1 in y_val_image: {count_y_val_image}\")\n",
    "print(f\"Number of labels that are 1 in y_test_image: {count_y_test_image}\")\n",
    "\n",
    "print(f\"Number of labels that are 1 in y_train_meta: {count_y_train_meta}\")\n",
    "print(f\"Number of labels that are 1 in y_val_meta: {count_y_val_meta}\")\n",
    "print(f\"Number of labels that are 1 in y_test_meta: {count_y_test_meta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0fbc30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_combined(image_path, metadata, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (128, 128))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return (image, metadata), label\n",
    "\n",
    "def create_combined_dataset(image_paths, metadata, labels, batch_size=32, shuffle=True):\n",
    "    image_paths = tf.constant(image_paths)\n",
    "    metadata = tf.convert_to_tensor(metadata, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((image_paths, metadata, labels))\n",
    "    ds = ds.map(preprocess_combined, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1000)\n",
    "\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fc020661",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_combined_dataset(X_train_image, X_train_meta, y_train_image, batch_size=256)\n",
    "val_ds = create_combined_dataset(X_val_image, X_val_meta, y_val_image, batch_size=256, shuffle=False)\n",
    "test_ds = create_combined_dataset(X_test_image, X_test_meta, y_test_image, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2e796",
   "metadata": {},
   "source": [
    "### CNN + MLP ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37d8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN Model\n",
    "def CNN_model(input_shape=(128, 128, 3)):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Fine-tune the base model\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Define additional layers for your specific task\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    # Create model\n",
    "    model = models.Model(inputs=base_model.input, outputs=output, name='cnn_model')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# MLP Model\n",
    "def MLP_model(input_dim):\n",
    "    inputs = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(df_meta.shape[1], activation='relu')(x)\n",
    "    \n",
    "    return models.Model(inputs=inputs, outputs=x, name='metadata_model')\n",
    "\n",
    "\n",
    "# Combined Model\n",
    "def build_combined_model(image_shape, metadata_dim):\n",
    "    cnn_model = CNN_model(image_shape)\n",
    "    mlp_model = MLP_model(metadata_dim)\n",
    "\n",
    "    # Flatten the CNN output to make it 2D\n",
    "    cnn_flattened = layers.Flatten()(cnn_model.output)\n",
    "\n",
    "    # Fusion\n",
    "    combined = layers.concatenate([cnn_flattened, mlp_model.output])\n",
    "    x = layers.Dense(64, activation='relu')(combined)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)  # Connect the output layer to `x`\n",
    "\n",
    "    model = models.Model(inputs=[cnn_model.input, mlp_model.input], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6e281a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "Epoch 1/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 7s/step - accuracy: 0.4923 - loss: 29.4129 - val_accuracy: 0.4957 - val_loss: 12.4549\n",
      "Epoch 2/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5s/step - accuracy: 0.5343 - loss: 26.1383 - val_accuracy: 0.5043 - val_loss: 5.6733\n",
      "Epoch 3/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4999 - loss: 22.8242 - val_accuracy: 0.4522 - val_loss: 5.6749\n",
      "Epoch 4/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5113 - loss: 23.6085 - val_accuracy: 0.4435 - val_loss: 6.3099\n",
      "Epoch 5/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5120 - loss: 19.3157 - val_accuracy: 0.5130 - val_loss: 2.6353\n",
      "Epoch 6/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5223 - loss: 16.2858 - val_accuracy: 0.4870 - val_loss: 1.7309\n",
      "Epoch 7/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5172 - loss: 15.1542 - val_accuracy: 0.4870 - val_loss: 1.6034\n",
      "Epoch 8/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4917 - loss: 14.8387 - val_accuracy: 0.5652 - val_loss: 1.7428\n",
      "Epoch 9/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5335 - loss: 13.8637 - val_accuracy: 0.5478 - val_loss: 1.8313\n",
      "Epoch 10/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5172 - loss: 11.6702 - val_accuracy: 0.5304 - val_loss: 1.7152\n",
      "Epoch 11/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4846 - loss: 12.0538 - val_accuracy: 0.5565 - val_loss: 1.6076\n",
      "Epoch 12/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4897 - loss: 10.0783 - val_accuracy: 0.5652 - val_loss: 1.5996\n",
      "Epoch 13/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4949 - loss: 10.8151 - val_accuracy: 0.5913 - val_loss: 1.5958\n",
      "Epoch 14/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.4809 - loss: 9.8109 - val_accuracy: 0.6087 - val_loss: 1.7087\n",
      "Epoch 15/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4911 - loss: 8.9188 - val_accuracy: 0.5478 - val_loss: 2.1503\n",
      "Epoch 16/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4971 - loss: 7.9004 - val_accuracy: 0.5565 - val_loss: 2.8774\n",
      "Epoch 17/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.4738 - loss: 8.7976 - val_accuracy: 0.5652 - val_loss: 2.8405\n",
      "Epoch 18/50\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.5273 - loss: 8.3083 - val_accuracy: 0.5739 - val_loss: 2.2801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x281e390a890>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_combined_model(image_shape=(128, 128, 3), metadata_dim=X_train_meta.shape[1])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e6bbfc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('combined_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f84aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f621af47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n"
     ]
    }
   ],
   "source": [
    "test_probs = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bedfd9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probs = np.array(test_probs).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "1e989015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84868443 0.97236824 0.7999439  0.9974397  0.7955228  0.5446944\n",
      " 0.999993   0.9996972  0.9982468  0.9852962  0.999282   0.98506826\n",
      " 0.5989156  0.6915302  0.99372274 0.9565421  0.9104082  0.99957037\n",
      " 0.6412609  0.8872931  0.88973796 0.97913855 0.97634286 0.8987821\n",
      " 0.79866344 0.83635986 0.99531996 0.94779897 0.9989159  0.6409503\n",
      " 0.9959075  0.9970083  0.9979337  0.99996084 0.9995498  0.57624745\n",
      " 0.8535459  0.88031375 0.8271381  0.9976287  0.99488074 0.78674966\n",
      " 0.7334769  0.8972581  0.95615476 0.9935225  0.99963725 0.99365145\n",
      " 0.5620816  0.76684374 0.9997043  0.97932804 0.90384054 0.9965025\n",
      " 0.9292059  0.99550164 0.99961144 0.56336796 0.99863315 0.99911946\n",
      " 0.9335121  0.9999565  0.99916315 0.99842614 0.8790202  0.9801121 ]\n"
     ]
    }
   ],
   "source": [
    "print(test_probs[test_probs > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "6a0f8f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695ms/step - accuracy: 0.5259 - loss: 1.5655\n",
      "Test Loss: 1.565483570098877\n",
      "Test Accuracy: 0.5258620977401733\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "41a0171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2814c81a740>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Assuming test_probs contains the predicted probabilities, we convert them to binary predictions\n",
    "y_pred = (test_probs > 0.5).astype(int)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test_image, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8a98d42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set - Labels with 1: 267, Labels with 0: 272\n",
      "Validation set - Labels with 1: 57, Labels with 0: 58\n",
      "Test set - Labels with 1: 57, Labels with 0: 59\n"
     ]
    }
   ],
   "source": [
    "# Count labels with 1 and 2 in each set\n",
    "count_y_train_image_1 = np.sum(y_train_image == 1)\n",
    "count_y_train_image_2 = np.sum(y_train_image == 0)\n",
    "\n",
    "count_y_val_image_1 = np.sum(y_val_image == 1)\n",
    "count_y_val_image_2 = np.sum(y_val_image == 0)\n",
    "\n",
    "count_y_test_image_1 = np.sum(y_test_image == 1)\n",
    "count_y_test_image_2 = np.sum(y_test_image == 0)\n",
    "\n",
    "print(f\"Train set - Labels with 1: {count_y_train_image_1}, Labels with 0: {count_y_train_image_2}\")\n",
    "print(f\"Validation set - Labels with 1: {count_y_val_image_1}, Labels with 0: {count_y_val_image_2}\")\n",
    "print(f\"Test set - Labels with 1: {count_y_test_image_1}, Labels with 0: {count_y_test_image_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fe85d6",
   "metadata": {},
   "source": [
    "### Auto Encoder ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b85fa46",
   "metadata": {},
   "source": [
    "# Define the convolutional autoencoder architecture\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoding layers\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Decoding layers\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(input_shape[2], (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Encoder model\n",
    "encoder = Model(input_layer, encoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=1, batch_size=256, shuffle=True, validation_data=(X_val, X_val), callback=[early_stopping_callback])\n",
    "\n",
    "# Encode the validation data\n",
    "encoded_val = encoder.predict(X_val)\n",
    "\n",
    "# Detect anomalies using reconstruction loss\n",
    "reconstructed_val = autoencoder.predict(X_val)\n",
    "reconstruction_error = np.mean((X_val - reconstructed_val) ** 2, axis=(1, 2, 3))\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "threshold = reconstruction_error.mean() + 2 * reconstruction_error.std()\n",
    "\n",
    "# Identify anomalies\n",
    "anomalies = reconstruction_error > threshold\n",
    "print(\"Number of anomalies detected:\", anomalies.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d61fe7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
