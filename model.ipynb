{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3b6be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16912a19",
   "metadata": {},
   "source": [
    "### Get Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aac1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_image = pd.read_csv('label_and_path.csv')\n",
    "X_image = df_image[:10000]['image_path'].values\n",
    "\n",
    "df_meta = pd.read_csv('skin_data.csv')\n",
    "X_meta = df_meta[:10000].drop(columns=['target', 'image_path']).values\n",
    "\n",
    "y = df_image[:10000]['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd048dbb",
   "metadata": {},
   "source": [
    "### Split Data ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "975f681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split for images\n",
    "X_train_image, X_val_test_image, y_train_image, y_val_test_image = train_test_split(X_image, y, test_size=0.3)\n",
    "X_val_image, X_test_image, y_val_image, y_test_image = train_test_split(X_val_test_image, y_val_test_image, test_size=0.5)\n",
    "\n",
    "# Split for metadata\n",
    "X_train_meta, X_val_test_meta, y_train_meta, y_val_test_meta = train_test_split(X_meta, y, test_size=0.3)\n",
    "X_val_meta, X_test_meta, y_val_meta, y_test_meta = train_test_split(X_val_test_meta, y_val_test_meta, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fbc30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_combined(image_path, metadata, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, (128, 128))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return (image, metadata), label\n",
    "\n",
    "def create_combined_dataset(image_paths, metadata, labels, batch_size=32, shuffle=True):\n",
    "    image_paths = tf.constant(image_paths)\n",
    "    metadata = tf.convert_to_tensor(metadata, dtype=tf.float32)\n",
    "    labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((image_paths, metadata, labels))\n",
    "    ds = ds.map(preprocess_combined, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1000)\n",
    "\n",
    "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc020661",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_combined_dataset(X_train_image, X_train_meta, y_train_image, batch_size=256)\n",
    "val_ds = create_combined_dataset(X_val_image, X_val_meta, y_val_image, batch_size=256, shuffle=False)\n",
    "test_ds = create_combined_dataset(X_test_image, X_test_meta, y_test_image, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d2e796",
   "metadata": {},
   "source": [
    "### CNN + MLP ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f37d8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CNN Model\n",
    "def CNN_model(input_shape=(128, 128, 3)):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False  # Optional: fine-tune later\n",
    "    \n",
    "    x = MaxPooling2D()(base_model.output)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    return Model(inputs=base_model.input, outputs=x, name='cnn_model')\n",
    "\n",
    "\n",
    "# MLP Model\n",
    "def MLP_model(input_dim):\n",
    "    inputs = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(inputs)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(df_meta.shape[1], activation='relu')(x)\n",
    "    \n",
    "    return models.Model(inputs=inputs, outputs=x, name='metadata_model')\n",
    "\n",
    "\n",
    "# Combined Model\n",
    "def build_combined_model(image_shape, metadata_dim):\n",
    "    cnn_model = CNN_model(image_shape)\n",
    "    mlp_model = MLP_model(metadata_dim)\n",
    "\n",
    "    # Flatten the CNN output to make it 2D\n",
    "    cnn_flattened = layers.Flatten()(cnn_model.output)\n",
    "\n",
    "    # Fusion\n",
    "    combined = layers.concatenate([cnn_flattened, mlp_model.output])\n",
    "    x = layers.Dense(64, activation='relu')(combined)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)  # Connect the output layer to `x`\n",
    "\n",
    "    model = models.Model(inputs=[cnn_model.input, mlp_model.input], outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e281a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 4s/step - accuracy: 0.9882 - loss: 0.3382 - val_accuracy: 0.9980 - val_loss: 0.3336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x229749f8160>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_combined_model(image_shape=(128, 128, 3), metadata_dim=X_train_meta.shape[1])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=1,\n",
    "    callbacks=[early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a0f8f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.9994 - loss: 0.1187 \n",
      "Test Loss: 0.26201409101486206\n",
      "Test Accuracy: 0.9986666440963745\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fe85d6",
   "metadata": {},
   "source": [
    "### Auto Encoder ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b85fa46",
   "metadata": {},
   "source": [
    "# Define the convolutional autoencoder architecture\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Input layer\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Encoding layers\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# Decoding layers\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(input_shape[2], (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# Autoencoder model\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "\n",
    "# Encoder model\n",
    "encoder = Model(input_layer, encoded)\n",
    "\n",
    "# Compile the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(X_train, X_train, epochs=1, batch_size=256, shuffle=True, validation_data=(X_val, X_val), callback=[early_stopping_callback])\n",
    "\n",
    "# Encode the validation data\n",
    "encoded_val = encoder.predict(X_val)\n",
    "\n",
    "# Detect anomalies using reconstruction loss\n",
    "reconstructed_val = autoencoder.predict(X_val)\n",
    "reconstruction_error = np.mean((X_val - reconstructed_val) ** 2, axis=(1, 2, 3))\n",
    "\n",
    "# Set a threshold for anomaly detection\n",
    "threshold = reconstruction_error.mean() + 2 * reconstruction_error.std()\n",
    "\n",
    "# Identify anomalies\n",
    "anomalies = reconstruction_error > threshold\n",
    "print(\"Number of anomalies detected:\", anomalies.sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs178",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
